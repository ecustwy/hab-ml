{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "from PIL import Image\n",
    "import sys\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HabDataset(Dataset):\n",
    "    \"\"\"HAB Images dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "        \"\"\"\n",
    "        self.images_data_frame = pd.read_csv(csv_file)\n",
    "        self.class_names = sorted(self.images_data_frame.iloc[:, 1].unique())\n",
    "        self.class_weights = torch.FloatTensor(1 / self.images_data_frame.iloc[:, 1].value_counts(normalize=True).sort_index())\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        img_path = self.images_data_frame.iloc[idx, 0]\n",
    "        \n",
    "        image = Image.open(img_path)\n",
    "        label_name = self.images_data_frame.iloc[idx, 1]\n",
    "        label = self.class_names.index(label_name)\n",
    "         \n",
    "        if self.transform:\n",
    "             image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Acantharea', 'Aggregate', 'Akashiwo', 'BadImageSegmentation', 'Bubble', 'Ceratium falcatiforme fusus pair', 'Ceratium falcatiforme fusus single', 'Ceratium furca pair', 'Ceratium furca side', 'Ceratium furca single', 'Ceratium other pair', 'Ceratium other single', 'Chaetoceros socialis', 'Chattonella', 'Ciliates', 'Cochlodinium Alexandrium Gonyaulax Gymnodinium chain', 'Cochlodinium Alexandrium Gonyaulax Gymnodinium pair', 'Curved diatom chain chaetoceros', 'Curved diatom chain guinardia', 'Dinophysis pair', 'Dinophysis single', 'Eucampia chain', 'Eucampia pair', 'Gymnodinium', 'Gyrodinium', 'Kelp Fragment', 'Licmophora', 'Lingulodinium', 'Marine Lashes', 'Nauplii', 'Phaeocystis', 'Polykrikos', 'Prorocentrum', 'Prorocentrum gracile', 'Protoperidinium', 'Protoperidinium feeding', 'Protoperidinium flipped', 'Pseudo nitzschia chain', 'Rhizosolenia or Proboscia', 'Sand', 'Straight diatom chains chaetoceros', 'Straight diatom chains hemiaulus', 'Straight diatom chains leptocylindrus epiphytes', 'Straight diatom chains with epiphytes', 'Thalassionema or Thalassiothrix chain', 'Thalassiosira chain', 'Torodinium', 'Unknown centric diatom', 'Unknown dinoflagellates elongated', 'Unknown dinoflagellates spherical', 'Unknown pennate diatom']\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/data6/SuryaKrishnan/raw_data\"\n",
    "\n",
    "image_datasets = {x: HabDataset(os.path.join(data_dir, (x + '.csv')),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].class_names\n",
    "print(class_names)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function definition to train our model\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=5):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = sys.maxsize\n",
    "    best_acc = 0.0\n",
    "    best_mean_class_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            running_preds = np.array([])\n",
    "            running_labels = np.array([])\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device) \n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    \n",
    "                    running_preds = np.append(running_preds, preds.cpu())\n",
    "                    running_labels = np.append(running_labels, labels.cpu())\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics to keep a tab on Loss and number of correct predictions\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "\n",
    "            # Calculating Model Performance Statistics \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]        \n",
    "            conf_matrix = confusion_matrix(running_labels, running_preds)\n",
    "            epoch_mean_class_acc = np.array(conf_matrix.diagonal() / conf_matrix.sum(axis=1)).mean()\n",
    "\n",
    "            # Logging Model Statistics to TensorBoard\n",
    "            if phase == \"train\":\n",
    "                scheduler.step()\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f} Mean Class Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc, epoch_mean_class_acc))\n",
    "\n",
    "            # Storing best model's weights\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_acc = epoch_acc\n",
    "                best_mean_class_acc = epoch_mean_class_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Loss: {:4f}'.format(best_loss))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "    print('Best val Mean Class Acc: {:4f}'.format(best_mean_class_acc))\n",
    "\n",
    "    stats_dict={\"Loss\" : best_loss, \"Accuracy\" : best_acc, \"Mean Class Accuracy\" : best_mean_class_acc}\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, stats_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_conv = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# freeze weights\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Adding custom fully connected layer\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "model_conv.fc = nn.Linear(num_ftrs, 51)\n",
    "\n",
    "model_conv = model_conv.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setting hyper params for model training\n",
    "\n",
    "params_dict = {\"lr_val\":0.01, \"momentum_val\":0.9, \"step_val\":7, \"gamma_val\":0.1, \"total_epochs\":25, \n",
    "    \"weights\":image_datasets['train'].class_weights.to(device)}\n",
    "\n",
    "# Handling Class Imbalance through Weighted Cross-Entropy Loss Function\n",
    "criterion = nn.CrossEntropyLoss(weight = params_dict[\"weights\"])\n",
    "\n",
    "# Selecting the Optimizer and Scheduler to use\n",
    "optimizer_conv = optim.SGD(model_conv.parameters(), lr=params_dict[\"lr_val\"], momentum=params_dict[\"momentum_val\"])\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=params_dict[\"step_val\"], gamma=params_dict[\"gamma_val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 2.9780 Acc: 0.5333 Mean Class Acc: 0.4321\n",
      "val Loss: 2.4379 Acc: 0.6188 Mean Class Acc: 0.5246\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 1.9093 Acc: 0.6684 Mean Class Acc: 0.6111\n",
      "val Loss: 1.8971 Acc: 0.6949 Mean Class Acc: 0.6145\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 1.6794 Acc: 0.6928 Mean Class Acc: 0.6526\n",
      "val Loss: 2.1372 Acc: 0.6639 Mean Class Acc: 0.6011\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 1.5537 Acc: 0.7147 Mean Class Acc: 0.6753\n",
      "val Loss: 2.5204 Acc: 0.7079 Mean Class Acc: 0.5846\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 1.4470 Acc: 0.7279 Mean Class Acc: 0.7000\n",
      "val Loss: 2.0480 Acc: 0.7478 Mean Class Acc: 0.6174\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 1.3110 Acc: 0.7385 Mean Class Acc: 0.7190\n",
      "val Loss: 2.3484 Acc: 0.7127 Mean Class Acc: 0.6143\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 1.2642 Acc: 0.7469 Mean Class Acc: 0.7302\n",
      "val Loss: 2.3727 Acc: 0.6948 Mean Class Acc: 0.6200\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 1.2221 Acc: 0.7559 Mean Class Acc: 0.7461\n",
      "val Loss: 2.2420 Acc: 0.7608 Mean Class Acc: 0.6387\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.6195 Acc: 0.8237 Mean Class Acc: 0.8319\n",
      "val Loss: 1.8535 Acc: 0.7935 Mean Class Acc: 0.6680\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.5606 Acc: 0.8261 Mean Class Acc: 0.8419\n",
      "val Loss: 1.8068 Acc: 0.7957 Mean Class Acc: 0.6627\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.5415 Acc: 0.8307 Mean Class Acc: 0.8465\n",
      "val Loss: 1.7417 Acc: 0.7953 Mean Class Acc: 0.6731\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.5141 Acc: 0.8321 Mean Class Acc: 0.8494\n",
      "val Loss: 1.7427 Acc: 0.8040 Mean Class Acc: 0.6671\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.4971 Acc: 0.8361 Mean Class Acc: 0.8554\n",
      "val Loss: 1.7745 Acc: 0.7966 Mean Class Acc: 0.6612\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.4822 Acc: 0.8361 Mean Class Acc: 0.8602\n",
      "val Loss: 1.8260 Acc: 0.7931 Mean Class Acc: 0.6637\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.4866 Acc: 0.8319 Mean Class Acc: 0.8507\n",
      "val Loss: 1.7136 Acc: 0.7980 Mean Class Acc: 0.6693\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.4445 Acc: 0.8374 Mean Class Acc: 0.8622\n",
      "val Loss: 1.7248 Acc: 0.7983 Mean Class Acc: 0.6687\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.4358 Acc: 0.8383 Mean Class Acc: 0.8606\n",
      "val Loss: 1.7260 Acc: 0.8013 Mean Class Acc: 0.6669\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.4456 Acc: 0.8409 Mean Class Acc: 0.8607\n",
      "val Loss: 1.8150 Acc: 0.7997 Mean Class Acc: 0.6651\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.4326 Acc: 0.8414 Mean Class Acc: 0.8645\n",
      "val Loss: 1.7229 Acc: 0.7965 Mean Class Acc: 0.6641\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.4354 Acc: 0.8406 Mean Class Acc: 0.8653\n",
      "val Loss: 1.7428 Acc: 0.7983 Mean Class Acc: 0.6614\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.4246 Acc: 0.8426 Mean Class Acc: 0.8639\n",
      "val Loss: 1.7154 Acc: 0.8008 Mean Class Acc: 0.6720\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.4277 Acc: 0.8414 Mean Class Acc: 0.8615\n",
      "val Loss: 1.7563 Acc: 0.8024 Mean Class Acc: 0.6661\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.4403 Acc: 0.8433 Mean Class Acc: 0.8598\n",
      "val Loss: 1.7186 Acc: 0.8001 Mean Class Acc: 0.6697\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.4396 Acc: 0.8415 Mean Class Acc: 0.8619\n",
      "val Loss: 1.7158 Acc: 0.7997 Mean Class Acc: 0.6669\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.4265 Acc: 0.8440 Mean Class Acc: 0.8687\n",
      "val Loss: 1.7366 Acc: 0.8047 Mean Class Acc: 0.6629\n",
      "\n",
      "Training complete in 61m 4s\n",
      "Best val Loss: 1.713618\n",
      "Best val Acc: 0.797981\n",
      "Best val Mean Class Acc: 0.669272\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model_conv, stats_dict = train_model(model_conv, criterion, optimizer_conv,\n",
    "                         exp_lr_scheduler, num_epochs=params_dict[\"total_epochs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run inference\n",
    "# Inference mode Function (Prediction) for Validation Set- Completely Unseen Data\n",
    "\n",
    "def run_inference(model):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    running_preds = np.array([])\n",
    "    running_labels = np.array([])\n",
    "    log_softmax_layer = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    for inputs, labels in dataloaders[\"val\"]:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        outputs = log_softmax_layer(outputs)\n",
    "        \n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        running_preds = np.append(running_preds, preds.cpu())\n",
    "        running_labels = np.append(running_labels, labels.cpu())\n",
    "    \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / dataset_sizes[\"val\"]\n",
    "    epoch_acc = running_corrects.double() / dataset_sizes[\"val\"]\n",
    "    conf_matrix = confusion_matrix(running_labels, running_preds)\n",
    "    epoch_mean_class_acc = np.array(conf_matrix.diagonal() / conf_matrix.sum(axis=1)).mean()\n",
    "\n",
    "    print('{} Loss: {:.4f} Acc: {:.4f} mean class acc: {:.4f}'.format(\n",
    "                \"Inference\", epoch_loss, epoch_acc, epoch_mean_class_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"/data6/SuryaKrishnan/raw_data\"\n",
    "\n",
    "image_datasets = HabDataset(data_dir, data_transforms[\"val\"])\n",
    "\n",
    "dataloaders = torch.utils.data.DataLoader(image_datasets[x], batch_size=32,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              \n",
    "\n",
    "\n",
    "# Run inference on the best model\n",
    "good_model = torch.load(\"./awesome_model_full\")\n",
    "good_model.eval()\n",
    "\n",
    "run_inference(good_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
